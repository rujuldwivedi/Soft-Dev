{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This is the actual file that trains the model based on the augmented data from the data augmentation file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('player_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['MP', 'Starts', 'Min', '90s', 'Gls', 'Ast', 'G-PK', 'PK', 'PKatt', \n",
    "            'CrdY', 'CrdR', 'xG', 'npxG', 'xAG', 'npxG+xAG', \n",
    "            'PrgC', 'PrgP', 'PrgR']\n",
    "\n",
    "df['Goals_per_90'] = df['Gls'] / df['90s']\n",
    "df['Assists_per_90'] = df['Ast'] / df['90s']\n",
    "df['xG_per_90'] = df['xG'] / df['90s']\n",
    "df['xAG_per_90'] = df['xAG'] / df['90s']\n",
    "df['PrgC_per_90'] = df['PrgC'] / df['90s']\n",
    "df['PrgP_per_90'] = df['PrgP'] / df['90s']\n",
    "df['PrgR_per_90'] = df['PrgR'] / df['90s']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the features list to include the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features += ['Goals_per_90', 'Assists_per_90', 'xG_per_90', 'xAG_per_90', \n",
    "             'PrgC_per_90', 'PrgP_per_90', 'PrgR_per_90']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define weights for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = {\n",
    "    'MP': 1,\n",
    "    'Starts': 1,\n",
    "    'Min': 1,\n",
    "    '90s': 1,\n",
    "    'Gls': 1,\n",
    "    'Ast': 3,  # Increase importance for assists\n",
    "    'G-PK': 1,\n",
    "    'PK': 1,\n",
    "    'PKatt': 1,\n",
    "    'CrdY': 0.5,  # Lower importance for yellow cards\n",
    "    'CrdR': 0.5,  # Lower importance for red cards\n",
    "    'xG': 2,  # Assign importance based on expected goals\n",
    "    'npxG': 2,\n",
    "    'xAG': 3,  # Increase importance for expected assists\n",
    "    'npxG+xAG': 2,\n",
    "    'PrgC': 1,\n",
    "    'PrgP': 1,\n",
    "    'PrgR': 1,\n",
    "    'Goals_per_90': 1,\n",
    "    'Assists_per_90': 3,\n",
    "    'xG_per_90': 2,\n",
    "    'xAG_per_90': 3,\n",
    "    'PrgC_per_90': 1,\n",
    "    'PrgP_per_90': 1,\n",
    "    'PrgR_per_90': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply weights to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_df = pd.DataFrame()\n",
    "for feature in features:\n",
    "    weighted_df[feature] = df[feature] * feature_weights[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a simple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input features and target variables\n",
    "X = weighted_df\n",
    "y = df[['Gls', 'Ast']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothetical scenario: Predict after 50 matches\n",
    "hypothetical_matches = 50\n",
    "\n",
    "# Create an empty DataFrame to store predictions for each player\n",
    "predictions_df = pd.DataFrame(columns=['Player', 'Predicted_Gls', 'Predicted_Ast'])\n",
    "\n",
    "# Iterate through each player in the dataset\n",
    "for index, player_data in df.iterrows():\n",
    "    # Adjust MP for the hypothetical scenario, considering a limit of 50 matches\n",
    "    hypothetical_data = pd.DataFrame({\n",
    "        'MP': [min(hypothetical_matches, player_data['MP'])],\n",
    "        'Starts': [player_data['Starts']],\n",
    "        'Min': [player_data['Min']],\n",
    "        '90s': [player_data['90s']],\n",
    "        'Gls': [player_data['Gls']],\n",
    "        'Ast': [player_data['Ast']],\n",
    "        'G-PK': [player_data['G-PK']],\n",
    "        'PK': [player_data['PK']],\n",
    "        'PKatt': [player_data['PKatt']],\n",
    "        'CrdY': [player_data['CrdY']],\n",
    "        'CrdR': [player_data['CrdR']],\n",
    "        'xG': [player_data['xG']],\n",
    "        'npxG': [player_data['npxG']],\n",
    "        'xAG': [player_data['xAG']],\n",
    "        'npxG+xAG': [player_data['npxG+xAG']],\n",
    "        'PrgC': [player_data['PrgC']],\n",
    "        'PrgP': [player_data['PrgP']],\n",
    "        'PrgR': [player_data['PrgR']],\n",
    "        'Goals_per_90': [player_data['Goals_per_90']],\n",
    "        'Assists_per_90': [player_data['Assists_per_90']],\n",
    "        'xG_per_90': [player_data['xG_per_90']],\n",
    "        'xAG_per_90': [player_data['xAG_per_90']],\n",
    "        'PrgC_per_90': [player_data['PrgC_per_90']],\n",
    "        'PrgP_per_90': [player_data['PrgP_per_90']],\n",
    "        'PrgR_per_90': [player_data['PrgR_per_90']]\n",
    "    })\n",
    "\n",
    "    # Apply weights to the hypothetical data\n",
    "    hypothetical_data_weighted = hypothetical_data * [feature_weights[feature] for feature in features]\n",
    "    hypothetical_data_scaled = scaler.transform(hypothetical_data_weighted)\n",
    "\n",
    "    predictions_hypothetical = model.predict(hypothetical_data_scaled)\n",
    "    predictions_hypothetical = predictions_hypothetical.clip(min=0)\n",
    "    predictions_hypothetical = predictions_hypothetical.round(2)\n",
    "    predictions_hypothetical = predictions_hypothetical / player_data['MP'] * hypothetical_matches\n",
    "\n",
    "    predictions_df = pd.concat([predictions_df, pd.DataFrame({\n",
    "        'Player': [player_data['Player']],\n",
    "        'Predicted_Gls': [predictions_hypothetical[0, 0]],\n",
    "        'Predicted_Ast': [predictions_hypothetical[0, 1]]\n",
    "    })], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Player  Predicted_Gls  Predicted_Ast  Total_Predicted\n",
      "2       Jude Bellingham             30             10               40\n",
      "9       Vinicius Júnior             21             15               36\n",
      "11               Joselu             18              9               27\n",
      "12           Toni Kroos              4             19               23\n",
      "13          Luka Modrić              2             19               21\n",
      "1     Federico Valverde              8              9               17\n",
      "4         Dani Carvajal              5             11               16\n",
      "10          Fran Garcia              2             12               14\n",
      "7               Rodrygo              8              5               13\n",
      "0       Antonio Rüdiger              7              4               11\n",
      "5           David Alaba              2              5                7\n",
      "6   Aurélien Tchouaméni              4              2                6\n",
      "3     Kepa Arrizabalaga              2              2                4\n",
      "8     Eduardo Camavinga              1              2                3\n"
     ]
    }
   ],
   "source": [
    "# Rounding off the predictions to the ceiling integer\n",
    "predictions_df['Predicted_Gls'] = predictions_df['Predicted_Gls'].apply(lambda x: int(x + 1))\n",
    "predictions_df['Predicted_Ast'] = predictions_df['Predicted_Ast'].apply(lambda x: int(x + 1))\n",
    "\n",
    "# Now arranging the players in descending order of predicted goals and assists\n",
    "predictions_df['Total_Predicted'] = predictions_df['Predicted_Gls'] + predictions_df['Predicted_Ast']\n",
    "predictions_df = predictions_df.sort_values(by='Total_Predicted', ascending=False)\n",
    "\n",
    "# Display the predictions for each player\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.217133333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rujul\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# To get rid of the warning, UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
    "# warnings.warn(\"X has feature names, but RandomForestRegressor was fitted without feature names\"), we need to use the following code\n",
    "model.feature_names_in_ = features\n",
    "\n",
    "\n",
    "# Calculate the mean squared error of the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
